{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Generator\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "VIDEO_PATH = Path(\"videos\") / Path(\"mk27.webm\")\n",
    "RAW_DATA_PATH = Path(\"data\") / Path(\"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_FROM = 0\n",
    "DEBUG_LIMIT = None\n",
    "FRAME_INTERVAL = 15\n",
    "TEXT_INTERVAL = 120\n",
    "FPS = 60\n",
    "\n",
    "\n",
    "class MyProcessor:\n",
    "    def __init__(self):\n",
    "        self.track_battle_start: int | None = None\n",
    "        self.caption_box_buffer: list[tuple[int, Image.Image]] = []\n",
    "\n",
    "        self.battles: list[tuple[int, int]] = []\n",
    "        self.captions: list[list[str]] = []\n",
    "\n",
    "    @staticmethod\n",
    "    def get_caption(caption_box: Image.Image):\n",
    "        caption_data: pd.DataFrame = pytesseract.image_to_data(\n",
    "            caption_box, output_type=pytesseract.Output.DATAFRAME\n",
    "        )\n",
    "        caption_data = caption_data[caption_data[\"conf\"] > 30].sort_values(\n",
    "            [\"word_num\", \"line_num\"]\n",
    "        )\n",
    "        lines_data = caption_data.groupby(\"line_num\")[\"text\"].apply(list)\n",
    "        caption_lines = [\" \".join(line) for line in lines_data.to_list()]\n",
    "        return caption_lines\n",
    "\n",
    "    def process_caption(self):\n",
    "        current_frame_num, current_box = self.caption_box_buffer[-1]\n",
    "        if len(self.captions) > 0:\n",
    "            _, prev_caption = self.captions[-1]\n",
    "        else:\n",
    "            prev_caption = None\n",
    "        current_caption = MyProcessor.get_caption(current_box)\n",
    "\n",
    "        if prev_caption != current_caption:\n",
    "            print(prev_caption, current_caption)\n",
    "            # something changed, process more detailed\n",
    "            for frame_num, caption_box in self.caption_box_buffer[:-1]:\n",
    "                caption = MyProcessor.get_caption(caption_box)\n",
    "                self.captions.append((frame_num, caption))\n",
    "        self.captions.append((current_frame_num, current_caption))\n",
    "\n",
    "    def process_frame(self, frame: cv2.typing.MatLike, frame_num: int):\n",
    "        if frame_num % FRAME_INTERVAL != 0:\n",
    "            return\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(frame_rgb)\n",
    "\n",
    "        width, height = image.size\n",
    "\n",
    "        # dimensions manually determined\n",
    "        # still cuts off some longer text...\n",
    "        caption_box = image.crop((width * 0.57, height * 0.88, width, height))\n",
    "        caption_box_data = np.array(caption_box)\n",
    "\n",
    "        # should be range [0, 255]\n",
    "        avg_intensity: float = caption_box_data.sum() / caption_box_data.size\n",
    "\n",
    "        # arbitrary threshold for determining battles\n",
    "        if avg_intensity < 50.0:\n",
    "            if self.track_battle_start is None:\n",
    "                print(f\"BEGIN BATTLE: {frame_num}\")\n",
    "                self.track_battle_start = frame_num\n",
    "                self.caption_box_buffer = []\n",
    "\n",
    "            if len(self.caption_box_buffer) >= TEXT_INTERVAL / FRAME_INTERVAL:\n",
    "                self.caption_box_buffer.pop(0)\n",
    "            self.caption_box_buffer.append((frame_num, caption_box))\n",
    "        else:\n",
    "            if self.track_battle_start:\n",
    "                print(f\"END BATTLE: {frame_num}\")\n",
    "                self.battles.append((self.track_battle_start, frame_num))\n",
    "                self.track_battle_start = None\n",
    "\n",
    "        # arbitrary threshold for determining if there is text\n",
    "        if (\n",
    "            self.track_battle_start is not None\n",
    "            and frame_num % TEXT_INTERVAL == 0\n",
    "            and avg_intensity > 4\n",
    "            and frame_num > self.track_battle_start + FRAME_INTERVAL\n",
    "        ):\n",
    "            self.process_caption()\n",
    "        # caption_box.save(f\"debug/{i}.jpg\")\n",
    "\n",
    "    def result(self) -> dict[str, pd.DataFrame]:\n",
    "        battles = [(start / FPS, end / FPS) for start, end in self.battles]\n",
    "        battles.sort(key=lambda x: x[0])\n",
    "\n",
    "        flattened_captions = []\n",
    "        for frame_num, caption_list in self.captions:\n",
    "            for caption in caption_list:\n",
    "                flattened_captions.append((frame_num, caption))\n",
    "\n",
    "        captions = []\n",
    "        prev_caption = None\n",
    "        for frame_num, caption in flattened_captions:\n",
    "            caption = caption.strip()\n",
    "            if caption != prev_caption and caption != \"\":\n",
    "                prev_caption = caption\n",
    "                captions.append((frame_num / FPS, caption))\n",
    "        return {\n",
    "            \"battles\": pd.DataFrame(battles, columns=[\"begin\", \"end\"]),\n",
    "            \"captions\": pd.DataFrame(captions, columns=[\"time\", \"text\"]),\n",
    "        }\n",
    "\n",
    "\n",
    "def iterate_video() -> Generator:\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    i = 0\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if i >= RESUME_FROM:\n",
    "                yield i, frame\n",
    "\n",
    "            i += 1\n",
    "\n",
    "            if DEBUG_LIMIT is not None and i >= RESUME_FROM + DEBUG_LIMIT:\n",
    "                break\n",
    "    finally:\n",
    "        print(f\"stopped at frame no: {i}\")\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = MyProcessor()\n",
    "for i, frame in tqdm(iterate_video()):\n",
    "    processor.process_frame(frame, i)\n",
    "result = processor.result()\n",
    "result[\"battles\"].to_csv(RAW_DATA_PATH / Path(\"battles.csv\"), index=False)\n",
    "result[\"captions\"].to_csv(RAW_DATA_PATH / Path(\"captions.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
